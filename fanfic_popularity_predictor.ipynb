{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fanfic_popularity_predictor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quicksilverri/fanfic-popularuty-prediction/blob/main/fanfic_popularity_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fanfiction parser\n",
        "\n",
        "This notebook is used to parse info about fanfiction from ArchiveOfOurOwn.com (AO3)"
      ],
      "metadata": {
        "id": "__Nsctrxc47-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import staff"
      ],
      "metadata": {
        "id": "T7y1NbXYYXxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh03JVW5YMRQ"
      },
      "outputs": [],
      "source": [
        "import requests as req\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from time import time, sleep\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse the data"
      ],
      "metadata": {
        "id": "UIkCfqZrnCRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marvel_link =  'https://archiveofourown.org/works?commit=Sort+and+Filter&work_search%5Bsort_column%5D=authors_to_sort_on&work_search%5Bother_tag_names%5D=&work_search%5Bexcluded_tag_names%5D=&work_search%5Bcrossover%5D=&work_search%5Bcomplete%5D=&work_search%5Bwords_from%5D=&work_search%5Bwords_to%5D=&work_search%5Bdate_from%5D=&work_search%5Bdate_to%5D=&work_search%5Bquery%5D=&work_search%5Blanguage_id%5D=&tag_id=Marvel'\n",
        "xmen_link = 'https://archiveofourown.org/works?work_search%5Bsort_column%5D=revised_at&work_search%5Bother_tag_names%5D=&exclude_work_search%5Bfreeform_ids%5D%5B%5D=11175&exclude_work_search%5Bfreeform_ids%5D%5B%5D=263297&work_search%5Bexcluded_tag_names%5D=&work_search%5Bcrossover%5D=&work_search%5Bcomplete%5D=&work_search%5Bwords_from%5D=&work_search%5Bwords_to%5D=&work_search%5Bdate_from%5D=&work_search%5Bdate_to%5D=&work_search%5Bquery%5D=&work_search%5Blanguage_id%5D=&commit=Sort+and+Filter&tag_id=Erik+Lehnsherr*s*Charles+Xavier'\n",
        "link = marvel_link\n",
        "pages = 1000"
      ],
      "metadata": {
        "id": "Qu3TE-5MHWgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Fanfic class\n",
        "\n",
        "It's kinda long and simple, so it's hidden. "
      ],
      "metadata": {
        "id": "9JGbR1f6QnSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(list): \n",
        "  \"\"\"Extracts text from list of bs4.Tags\"\"\"\n",
        "\n",
        "  return [item.get_text() for item in list]"
      ],
      "metadata": {
        "id": "DieUMyhp9rHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fanfic: \n",
        "  def __init__(self, fanfic):\n",
        "    self.fic = fanfic\n",
        "    self.info = {}\n",
        "\n",
        "    self.header = self.fic.select('.heading a')\n",
        "    \n",
        "    self.get_header()\n",
        "    self.get_chapters()\n",
        "    self.get_stats()\n",
        "    self.get_date()\n",
        "    self.get_tags()\n",
        "    self.get_square()\n",
        "\n",
        "  def get_header(self):\n",
        "    \"\"\"Sets title, author nickname and list of fandoms into self.stats dict\"\"\"\n",
        "    \n",
        "    self.info['title'] = self.header[0].get_text()\n",
        "    self.info['author'] = self.header[1].get_text()\n",
        "    self.info['fandoms'] = clean(self.header[2:])\n",
        "\n",
        "  def get_chapters(self): \n",
        "    \"\"\"Sets number of chapters written and number of chapters intended\n",
        "    into self.stats dict\"\"\"\n",
        "\n",
        "    def smart_int(n):\n",
        "      try: \n",
        "        return int(n)\n",
        "      except:\n",
        "        return None\n",
        "\n",
        "    chapters = self.fic.select('dd.chapters')[0].get_text()\n",
        "    written, total = map(smart_int, chapters.split('/'))\n",
        "\n",
        "    self.info['written'] = written\n",
        "    self.info['total'] = total\n",
        "\n",
        "  def get_number(self, selector): \n",
        "     \"\"\"Processes numerical data (removes comma so it can be turned\n",
        "     into integer)\"\"\"\n",
        "\n",
        "     try: \n",
        "\n",
        "       data = self.fic.select(selector)[0].get_text()\n",
        "       data = int(data.replace(',', ''))\n",
        "       return data\n",
        "        \n",
        "     except: return None\n",
        "\n",
        "  def get_stats(self): \n",
        "     \"\"\"Sets data collected in Stats section (words, hits, comments,\n",
        "     bookmarks, collections and language) into self.info dict\"\"\"\n",
        "\n",
        "     self.info['words'] = self.get_number('dd.words')\n",
        "     self.info['hits'] = self.get_number('dd.hits') \n",
        "     self.info['comments'] = self.get_number('dd.comments') \n",
        "     self.info['bookmarks'] = self.get_number('dd.bookmarks')\n",
        "     self.info['collections'] = self.get_number('dd.collections') \n",
        "     self.info['lang'] = self.fic.select('dd.language')[0].get_text()\n",
        "     self.info['kudos'] = self.get_number('.kudos a')\n",
        "\n",
        "  def get_date(self):  # add date of first publishing??\n",
        "    \"\"\"Sets date of the most recent update into self.dict\"\"\"\n",
        "\n",
        "    self.info['date'] = self.fic.select('.datetime')[0].get_text() \n",
        "    \n",
        "  def get_tags(self): \n",
        "    \"\"\"Sets tag-like data into self.info dict\"\"\"\n",
        "\n",
        "    self.info['characters'] = clean(self.fic.select('.characters a.tag'))\n",
        "    self.info['parings'] = clean(self.fic.select('.relationships a.tag'))\n",
        "    self.info['freeforms'] = clean(self.fic.select('.freeforms a.tag'))\n",
        "\n",
        "  def get_square(self): \n",
        "    \"\"\"Sets data from square to the left of fanfic title into self.info dict\"\"\"\n",
        "\n",
        "    self.info['rating'] = self.fic.select('.rating .text')[0].get_text()\n",
        "    self.info['category'] = clean(self.fic.select('.category .text'))\n",
        "    self.info['completion'] = self.fic.select('.iswip .text')[0].get_text()\n",
        "    self.info['warnings'] = clean(self.fic.select('.warnings a.tag'))\n",
        "\n",
        "  def get_info(self):\n",
        "     \"\"\"Return all the data about Fanfic in a DataFrame\"\"\"\n",
        "\n",
        "     df = pd.DataFrame([self.info])\n",
        "\n",
        "     return df"
      ],
      "metadata": {
        "id": "ZvMJhILFnIQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create FanficParser"
      ],
      "metadata": {
        "id": "Qxw67WczQrww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FanficParser: \n",
        "  def __init__(self, initial_link):\n",
        "    self.inlink = initial_link\n",
        "    self.domain = self.get_domain()\n",
        "    self.df = pd.DataFrame()\n",
        "    self.link = self.inlink\n",
        "    self.page = 1\n",
        "\n",
        "    self.fanfics = []\n",
        "\n",
        "  def get_domain(self):\n",
        "     end_of_link = self.inlink.find('/', 8)\n",
        "     domain = self.inlink[:end_of_link]\n",
        "     return domain\n",
        "  \n",
        "  def parse_page(self): \n",
        "    page = req.get(self.link)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    self.fanfics = soup.select('[role~=article]')\n",
        "\n",
        "    try: \n",
        "      new_link_relative = soup.select('li.next a')[0].get('href')\n",
        "      self.link = self.domain + new_link_relative\n",
        "\n",
        "      print(f'{self.page} parsed')\n",
        "      self.page += 1\n",
        "    \n",
        "    except: \n",
        "      print('page not parsed, let me wait a sec')\n",
        "      sleep(20)\n",
        "\n",
        "  def parse(self, n_pages): \n",
        "    start_time = time()\n",
        "    \n",
        "    for i in range(n_pages): \n",
        "      self.parse_page()\n",
        "      \n",
        "      for fanfic in self.fanfics:\n",
        "        self.df = self.df.append(Fanfic(fanfic).get_info())\n",
        "\n",
        "    print(f'total {self.df.shape[0]} fanfics')\n",
        "    self.df.index = range(self.df.shape[0])\n",
        "    \n",
        "    end_time = time()\n",
        "    print(f'time for execution {end_time - start_time}')\n",
        "\n",
        "  def reset(self):\n",
        "    self.df = pd.DataFrame()\n",
        "    self.link = self.inlink\n",
        "    self.page = 1\n",
        "    print('Parser resetted')"
      ],
      "metadata": {
        "id": "l-eetmC2_IgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse info"
      ],
      "metadata": {
        "id": "gahaw9O4o7Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = FanficParser(link)"
      ],
      "metadata": {
        "id": "q3NOz94GHfw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.parse(300)"
      ],
      "metadata": {
        "id": "sEBJ40ei_iBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = parser.df"
      ],
      "metadata": {
        "id": "Y9TM0mDgPpti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WVLPG7w2MU9",
        "outputId": "446e1132-9e0a-4d9f-9d18-971f665fee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11640, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('new_fanfics.csv')"
      ],
      "metadata": {
        "id": "HxogK3NPkAn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}